# 改善記録: PDFファイル保存不足の原因調査

**作成日時**: 2026-02-15 09:37:30  
**タスク**: 31.10 PDFファイル保存不足の原因調査（Critical）  
**優先度**: 🔴 Critical

## 問題の概要

2026-02-15の本番環境検証で、データ収集とS3保存に重大な不整合が発見されました：

- **Lambda Collectorログ**: 2,694件収集成功
- **S3バケット**: 998件のPDFファイルのみ保存
- **不足**: 約1,696件（63%）のPDFファイルが保存されていない

## 調査結果

### 1. コード分析

**処理フロー**:
```typescript
async function processDisclosure(metadata, execution_id, sequence) {
  try {
    const disclosure_id = generateDisclosureId(...);
    const s3_key = await downloadPdf(...);  // ← PDFダウンロード
    await saveMetadata(disclosure, s3_key); // ← メタデータ保存
    logger.info('Successfully processed disclosure', ...);
  } catch (error) {
    logger.error('Failed to process disclosure', ...);
    throw error;
  }
}
```

**重要な発見**:
- `downloadPdf` が失敗した場合、`saveMetadata` は実行されない
- したがって、「メタデータのみ保存、PDFなし」という状況は**理論上発生しない**
- しかし、本番環境では「DynamoDB 2,694件、S3 998件」という状況が発生している

### 2. 想定される根本原因

#### 原因A: collected_countのカウントロジックに問題がある（最も可能性が高い）

**仮説**:
- `processDisclosuresInParallel` 関数で `results.success++` がカウントされる条件が間違っている
- または、`scrapeTdnetList` で取得したメタデータ件数を `collected_count` としてカウントしている

**検証方法**:
```typescript
// handler.ts の collectDisclosuresForDateRange 関数
const disclosureMetadata = await scrapeTdnetList(date);
logger.info('TDnet list scraped successfully', {
  execution_id,
  date,
  count: disclosureMetadata.length, // ← ここでメタデータ件数をログ出力
});

const results = await processDisclosuresInParallel(disclosureMetadata, execution_id, 5);
collected_count += results.success; // ← ここで成功件数を加算
failed_count += results.failed;
```

**問題点**:
- `scrapeTdnetList` で取得したメタデータ件数（2,694件）をログ出力している
- しかし、実際に処理が成功したのは998件のみ
- `collected_count` のカウントロジックに問題がある可能性

#### 原因B: PDFダウンロードが失敗しているが、エラーが記録されていない

**仮説**:
- `downloadPdf` 内でエラーが発生しているが、ログに記録されていない
- または、エラーが発生しても例外がスローされず、空の `s3_key` が返されている

**検証方法**:
- CloudWatch Logsで「Failed to download PDF」エラーを検索
- エラーの種類と頻度を集計

#### 原因C: TDnetサイトからのPDFダウンロードが失敗している

**仮説**:
- TDnetサイトが404、403、500などのエラーを返している
- レート制限により一部のPDFダウンロードがスキップされている

**検証方法**:
- CloudWatch Logsで「404」「403」「500」「429」エラーを検索
- レート制限のログを確認

### 3. 調査スクリプト

以下のスクリプトを作成しました：

1. **scripts/analyze-cloudwatch-logs.ps1**
   - Lambda CollectorのCloudWatch Logsを分析
   - PDF保存失敗のエラーを検索
   - 収集成功件数と失敗件数を確認
   - S3 PutObject エラーを検索

2. **scripts/check-dynamodb-s3-consistency.ps1**
   - DynamoDBのレコード数をカウント
   - pdf_s3_keyが設定されているレコード数をカウント
   - S3バケットのオブジェクト数をカウント
   - 整合性チェック結果を表示

## 修正方針

### 優先度1: CloudWatch Logsの確認（即座に実施）

```powershell
# CloudWatch Logsを分析
scripts/analyze-cloudwatch-logs.ps1

# DynamoDBとS3の整合性を確認
scripts/check-dynamodb-s3-consistency.ps1
```

これらのスクリプトを実行して、以下の情報を取得します：
- PDF保存失敗の具体的なエラーメッセージ
- エラーの種類と頻度
- DynamoDBとS3の不整合の詳細

### 優先度2: カウントロジックの修正（原因特定後）

**原因Aが確認された場合**:
- `collected_count` のカウントロジックを修正
- `scrapeTdnetList` で取得したメタデータ件数ではなく、実際に処理が成功した件数をカウント

**原因Bが確認された場合**:
- `downloadPdf` のエラーハンドリングを強化
- エラーが発生した場合、必ずログに記録し、例外をスロー

**原因Cが確認された場合**:
- TDnetサイトのエラーレスポンスを適切に処理
- レート制限を調整（現在2秒間隔 → 3秒間隔に変更）

### 優先度3: データ整合性の回復（修正後）

1. **不足しているPDFファイルを再収集**
   ```powershell
   # DynamoDBからpdf_s3_keyが未設定のレコードを取得
   # 該当する開示情報のPDFを再ダウンロード
   scripts/recover-missing-pdfs.ps1
   ```

2. **整合性チェックを再実行**
   ```powershell
   scripts/check-dynamodb-s3-consistency.ps1
   ```

## 次のステップ

1. **即座に実施**: CloudWatch Logsの確認
   - `scripts/analyze-cloudwatch-logs.ps1` を実行
   - エラーメッセージを確認
   - 根本原因を特定

2. **原因特定後**: 修正タスクを追加
   - タスク31.10.5: カウントロジックの修正
   - タスク31.10.6: エラーハンドリングの強化
   - タスク31.10.7: データ整合性の回復

3. **修正後**: 再デプロイと検証
   - 修正をデプロイ
   - 初回データ収集を再実行
   - 整合性チェックを実施

## 関連ドキュメント

- **作業記録**: `.kiro/specs/tdnet-data-collector/work-logs/work-log-20260215-093248-pdf-save-investigation.md`
- **本番環境検証記録**: `.kiro/specs/tdnet-data-collector/work-logs/work-log-20260215-085941-production-verification.md`
- **エラーハンドリングパターン**: `.kiro/steering/core/error-handling-patterns.md`
- **Lambda実装ガイド**: `.kiro/steering/development/lambda-implementation.md`

## 申し送り事項

- CloudWatch Logsの確認は、ユーザーが実行する必要があります（AWS認証情報が必要）
- 調査スクリプトは英語メッセージに変更済み（文字エンコーディング問題を回避）
- 根本原因が特定されるまで、本番環境での新規データ収集は推奨しません
