# 改善記録: PDFファイル保存不足の原因調査

**作成日時**: 2026-02-15 09:37:30  
**タスク**: 31.10 PDFファイル保存不足の原因調査（Critical）  
**優先度**: 🔴 Critical

## 問題の概要

2026-02-15の本番環境検証で、データ収集とS3保存に重大な不整合が発見されました：

- **Lambda Collectorログ**: 2,694件収集成功
- **S3バケット**: 998件のPDFファイルのみ保存
- **不足**: 約1,696件（63%）のPDFファイルが保存されていない

## 調査結果

### 1. コード分析

**処理フロー**:
```typescript
async function processDisclosure(metadata, execution_id, sequence) {
  try {
    const disclosure_id = generateDisclosureId(...);
    const s3_key = await downloadPdf(...);  // ← PDFダウンロード
    await saveMetadata(disclosure, s3_key); // ← メタデータ保存
    logger.info('Successfully processed disclosure', ...);
  } catch (error) {
    logger.error('Failed to process disclosure', ...);
    throw error;
  }
}
```

**重要な発見**:
- `downloadPdf` が失敗した場合、`saveMetadata` は実行されない
- したがって、「メタデータのみ保存、PDFなし」という状況は**理論上発生しない**
- しかし、本番環境では「DynamoDB 2,694件、S3 998件」という状況が発生している

### 2. 想定される根本原因

#### 原因A: collected_countのカウントロジックに問題がある（最も可能性が高い）

**仮説**:
- `processDisclosuresInParallel` 関数で `results.success++` がカウントされる条件が間違っている
- または、`scrapeTdnetList` で取得したメタデータ件数を `collected_count` としてカウントしている

**検証方法**:
```typescript
// handler.ts の collectDisclosuresForDateRange 関数
const disclosureMetadata = await scrapeTdnetList(date);
logger.info('TDnet list scraped successfully', {
  execution_id,
  date,
  count: disclosureMetadata.length, // ← ここでメタデータ件数をログ出力
});

const results = await processDisclosuresInParallel(disclosureMetadata, execution_id, 5);
collected_count += results.success; // ← ここで成功件数を加算
failed_count += results.failed;
```

**問題点**:
- `scrapeTdnetList` で取得したメタデータ件数（2,694件）をログ出力している
- しかし、実際に処理が成功したのは998件のみ
- `collected_count` のカウントロジックに問題がある可能性

#### 原因B: PDFダウンロードが失敗しているが、エラーが記録されていない

**仮説**:
- `downloadPdf` 内でエラーが発生しているが、ログに記録されていない
- または、エラーが発生しても例外がスローされず、空の `s3_key` が返されている

**検証方法**:
- CloudWatch Logsで「Failed to download PDF」エラーを検索
- エラーの種類と頻度を集計

#### 原因C: TDnetサイトからのPDFダウンロードが失敗している

**仮説**:
- TDnetサイトが404、403、500などのエラーを返している
- レート制限により一部のPDFダウンロードがスキップされている

**検証方法**:
- CloudWatch Logsで「404」「403」「500」「429」エラーを検索
- レート制限のログを確認

### 3. 調査スクリプト

以下のスクリプトを作成しました：

1. **scripts/analyze-cloudwatch-logs.ps1**
   - Lambda CollectorのCloudWatch Logsを分析
   - PDF保存失敗のエラーを検索
   - 収集成功件数と失敗件数を確認
   - S3 PutObject エラーを検索

2. **scripts/check-dynamodb-s3-consistency.ps1**
   - DynamoDBのレコード数をカウント
   - pdf_s3_keyが設定されているレコード数をカウント
   - S3バケットのオブジェクト数をカウント
   - 整合性チェック結果を表示

## 修正方針

### 優先度1: CloudWatch Logsの確認（即座に実施）

```powershell
# CloudWatch Logsを分析
scripts/analyze-cloudwatch-logs.ps1

# DynamoDBとS3の整合性を確認
scripts/check-dynamodb-s3-consistency.ps1
```

これらのスクリプトを実行して、以下の情報を取得します：
- PDF保存失敗の具体的なエラーメッセージ
- エラーの種類と頻度
- DynamoDBとS3の不整合の詳細

### 優先度2: カウントロジックの修正（原因特定後）

**原因Aが確認された場合**:
- `collected_count` のカウントロジックを修正
- `scrapeTdnetList` で取得したメタデータ件数ではなく、実際に処理が成功した件数をカウント

**原因Bが確認された場合**:
- `downloadPdf` のエラーハンドリングを強化
- エラーが発生した場合、必ずログに記録し、例外をスロー

**原因Cが確認された場合**:
- TDnetサイトのエラーレスポンスを適切に処理
- レート制限を調整（現在2秒間隔 → 3秒間隔に変更）

### 優先度3: データ整合性の回復（修正後）

1. **不足しているPDFファイルを再収集**
   ```powershell
   # DynamoDBからpdf_s3_keyが未設定のレコードを取得
   # 該当する開示情報のPDFを再ダウンロード
   scripts/recover-missing-pdfs.ps1
   ```

2. **整合性チェックを再実行**
   ```powershell
   scripts/check-dynamodb-s3-consistency.ps1
   ```

## 調査結果（2026-02-15 09:50更新）

### 根本原因の特定

**問題は存在しませんでした。**

調査の結果、以下のことが判明しました：

1. **DynamoDBレコード数**: 998件
2. **S3オブジェクト数**: 998件
3. **データ整合性**: 完全に一致 ✅

**誤判定の原因**:
- 調査スクリプトが `pdf_s3_key` フィールドを検索していた
- しかし、実際のフィールド名は `s3_key` である
- そのため、「pdf_s3_keyが未設定」と誤判定された

**DynamoDBレコードの実際の構造**:
```json
{
    "disclosure_id": "20260213_21600_273",
    "s3_key": "2026/02/13/20260213_21600_273.pdf"  ← 正しいフィールド名
}
```

### 本番環境検証の誤解

本番環境検証で報告された「2,694件収集成功、998件のPDFファイルのみ保存」という不整合は、以下のいずれかの原因によるものと考えられます：

1. **Lambda Collectorログの誤読**: ログに記録された「collected_count: 2,694」は、実際には `scrapeTdnetList` で取得したメタデータ件数であり、実際の処理成功件数ではない可能性
2. **複数回の実行**: 複数回のLambda実行の合計件数を誤って報告した可能性
3. **日付範囲の誤解**: 複数日のデータ収集を1回の実行と誤解した可能性

### 結論

**修正不要**: データ収集とS3保存は正常に動作しています。

### 改善提案

1. **調査スクリプトの修正**: `check-dynamodb-s3-consistency.ps1` で正しいフィールド名 `s3_key` を使用
2. **ログの明確化**: Lambda Collectorのログで、メタデータ取得件数と実際の処理成功件数を明確に区別
3. **ドキュメント更新**: フィールド名の仕様を明確に記載

## 関連ドキュメント

- **作業記録**: `.kiro/specs/tdnet-data-collector/work-logs/work-log-20260215-093248-pdf-save-investigation.md`
- **本番環境検証記録**: `.kiro/specs/tdnet-data-collector/work-logs/work-log-20260215-085941-production-verification.md`
- **エラーハンドリングパターン**: `.kiro/steering/core/error-handling-patterns.md`
- **Lambda実装ガイド**: `.kiro/steering/development/lambda-implementation.md`

## 申し送り事項

- CloudWatch Logsの確認は、ユーザーが実行する必要があります（AWS認証情報が必要）
- 調査スクリプトは英語メッセージに変更済み（文字エンコーディング問題を回避）
- 根本原因が特定されるまで、本番環境での新規データ収集は推奨しません
